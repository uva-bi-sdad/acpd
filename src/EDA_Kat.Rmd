---
title: "EDA_Kat"
author: "Kateryna Savchyn"
date: "7/30/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r packages}
if (!("pacman" %in% installed.packages()[,1])) {
  install.packages(pkgs = "pacman")
}
pacman::p_load(tidyverse, maditr, httr, sf, geosphere, assertthat,
               measurements, here, ggplot2)
```

## Create Main Categories

```{r categories}
c <- here('data','acpd','Clarendon_details','clarendon_clean_01.csv')
clarendon_clean <- fread(c)
names(clarendon_clean) <- c('index', 'date', 'establishment', 'incident_type', 'day', 'num_cfs', 'num_arrests')
clarendon_clean$incident_type <- factor(gsub("[[:space:]]", "", clarendon_clean$incident_type))
clarendon_clean <- na.omit(clarendon_clean)


category_parser <- function(incident_type) {
  if (str_detect(string = incident_type,
                 pattern = "(?i)(NOISE|DISP|DISO|UIP|BAN|OPC|DIP)")) {
    "Disorderly Conduct"
  } else if (str_detect(string = incident_type,
                        pattern = "(?i)(IDCHECK|FAKEID|FAKE|ID)")) {
    "Identification"
  } else if (str_detect(string = incident_type,
                        pattern = "(?i)(FIGHT|MALWOUND|A&B|A&BMOB|A&BLEO)")) {
    "Assault"
  } else if (str_detect(string = incident_type,
                        pattern = "(?i)(DUI)")) {
    "DUI"
  } else if(is.na(incident_type)){
      "NA"
    } else {
    "Other"
    }
    }

clarendon_clean <- clarendon_clean %>% dt_mutate(main_category = factor(map_chr(.x = incident_type,
                                       .f = category_parser)))

cc <- here('data','acpd','Clarendon_details','clarendon_clean_02.csv')
write.csv(clarendon_clean, cc)
```

## Main Category Breakout

```{r cat break}
clean <- clarendon_clean %>% dt_filter(main_category != 'Other') 

ggplot(clean, aes(x = main_category, y = num_cfs/6319, fill = incident_type)) + geom_bar(stat = 'identity')  +
  theme_minimal() 
```


## Proportion of Arrests by Crime Type

```{r prop}
agg <- clean %>% group_by(main_category) %>% summarise(total = sum(num_cfs), arrests = sum(num_arrests))

agg %>% 
   gather(type, count, total:arrests) %>% 
   ggplot(., aes(x=reorder(main_category,-count), y=count, fill=forcats::fct_rev(type))) +
   geom_bar(stat="identity") + 
  ggtitle('Total Incidents and Arrests by Incident Type') + 
  xlab('Broad Category') + 
  ylab('Total Count (2016-2019)') + 
  labs(fill = "Proportions") + theme_bw()
```

## Proportion of Arrests by Crime Type 
```{r time prop}
agg <- clean %>% group_by(main_category) %>% summarise(proportion_arrested = sum(num_arrests)/sum(num_cfs), composition = sum(num_cfs)/6319) %>%
  gather(type, prop, proportion_arrested:composition)

ordered <- filter(agg, type == "composition") %>% arrange(prop)
agg$main_category2 <- factor(agg$main_category, levels = ordered$main_category)


g <- ggplot(agg, aes(x = main_category2, y = prop, fill = forcats::fct_rev(type))) +
      geom_bar(position = "dodge",stat="identity") + 
      ggtitle('Composition and Proportion of Arrests by Incident Type') + 
      xlab('Broad Category') + 
      ylab('Proportion (2016-2019)') + 
      labs(fill = "Proportions") + theme_bw()
g
```

## Crime over Time

```{r prop over time}
agg <- clean %>% group_by(year = factor(year(date)), main_category, month = month(date)) %>% 
  summarise(proportion_arrested = sum(num_arrests)/sum(num_cfs), total_arrests = sum(num_arrests),
            total_incidents = sum(num_cfs))

ggplot(agg,
       aes(x = month, y = total_incidents)) +
  geom_line(aes(color = year), size = 1) +
  theme_minimal() + 
  facet_grid(~main_category)
```

```{r  over time}
agg  <- clean %>% group_by(year  =  year(date), main_category)  %>% summarise(prop =  sum(num_arrests)/sum(num_cfs))
ggplot(clean, aes(x = year(date), y = num_arrests/num_cfs, fill = main_category)) + geom_bar(stat = 'identity')  +
  theme_minimal()
ggplot(agg, aes(x = year , y = prop, fill = main_category)) + geom_bar(stat = 'identity')  +
  theme_minimal()
```


## NLP on crime description versus crime category

```{r nlp}
library(rio)
library(NLP)
library(RColorBrewer)
library(tm)
library(wordcloud)
library(SnowballC)
library(stopwords)
d <- here('data', 'acpd','original', 'ARI Nightlife Detail Logs',  'Clarendon Detail Calls for Service 2016 - YTD.xlsx')
details <- import_list(d, setclass = "tbl", rbind = TRUE)

```

```{r  corpus}
corp <- details$Notes
corpus <- VCorpus(VectorSource(corp))

#clean lyrics data
corpus <- tm_map(corpus, stripWhitespace) 
corpus <- tm_map(corpus, content_transformer(tolower)) 

stopwords <- stopwords(language = "en", source = "smart")
corpus <- tm_map(corpus, removeWords, stopwords)
                           
corpus <- tm_map(corpus, stemDocument, language="english") 
corpus <- tm_map(corpus, removePunctuation)

## Create document term matrix
dtm <- DocumentTermMatrix(corpus)
## Remove sparse terms (aka terms that appear just once in the document etc)
dtms <-removeSparseTerms(dtm, 0.99)

## order the frequencies 
freq <- sort(colSums(as.matrix(dtms)), decreasing=T)

```

```{r overall cloud}
set.seed(200)
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "Field Notes: 2016 -  2019")

wordcloud(names(freq), freq, scale=c(6,.8), max.words=1000,
 random.order=F, use.r.layout= F,min.freq=50,
colors=brewer.pal(6, "Dark2"))
```

```{r cloud1 -  Disorderly  Conduct}
names(details) <-  c('date', 'dow', 'time', 'address', 'incident_type',  'arrest_type', 
                     'establishment', 'case_no', 'notes', 'suspect_sex')
det1 <- na.omit(details %>% dt_select(incident_type, notes)) %>% 
        dt_mutate(main_category = factor(map_chr(.x = incident_type,
                                       .f = category_parser)))  %>% dt_filter(main_category ==  'Identification')

det2 <- na.omit(details %>% dt_select(incident_type, notes)) %>% 
        dt_mutate(main_category = factor(map_chr(.x = incident_type,
                                       .f = category_parser)))  %>% dt_filter(main_category ==  'Assault')

det3 <- na.omit(details %>% dt_select(incident_type, notes)) %>% 
        dt_mutate(main_category = factor(map_chr(.x = incident_type,
                                       .f = category_parser)))  %>% dt_filter(main_category ==  'Disorderly Conduct')

det4 <- na.omit(details %>% dt_select(incident_type, notes)) %>% 
        dt_mutate(main_category = factor(map_chr(.x = incident_type,
                                       .f = category_parser)))  %>% dt_filter(main_category ==  'Other')
corp1 <- det1$notes
corp2 <- det2$notes
corp3 <- det3$notes
corp4 <- det4$notes
corpus1 <- VCorpus(VectorSource(corp1))
corpus2 <- VCorpus(VectorSource(corp2))
corpus3 <- VCorpus(VectorSource(corp3))
corpus4 <- VCorpus(VectorSource(corp4))

#clean data
corpus1 <- tm_map(corpus1, stripWhitespace)
corpus1 <- tm_map(corpus1, content_transformer(tolower)) 
corpus2 <- tm_map(corpus2, stripWhitespace)
corpus2 <- tm_map(corpus2, content_transformer(tolower)) 
corpus3 <- tm_map(corpus3, stripWhitespace)
corpus3 <- tm_map(corpus3, content_transformer(tolower)) 
corpus4 <- tm_map(corpus4, stripWhitespace)
corpus4 <- tm_map(corpus4, content_transformer(tolower)) 

stopwords <- stopwords(language = "en", source = "smart")
corpus1 <- tm_map(corpus1, removeWords, stopwords)
corpus2 <- tm_map(corpus2, removeWords, stopwords)
corpus3 <- tm_map(corpus3, removeWords, stopwords)
corpus4 <- tm_map(corpus4, removeWords, stopwords)
                           
corpus1 <- tm_map(corpus1, stemDocument, language="english") 
corpus1 <- tm_map(corpus1, removePunctuation)
corpus2 <- tm_map(corpus2, stemDocument, language="english") 
corpus2 <- tm_map(corpus2, removePunctuation)
corpus3 <- tm_map(corpus3, stemDocument, language="english") 
corpus3 <- tm_map(corpus3, removePunctuation)
corpus4 <- tm_map(corpus4, stemDocument, language="english") 
corpus4 <- tm_map(corpus4, removePunctuation)

## Create document term matrix
dtm1 <- DocumentTermMatrix(corpus1)
dtm2 <- DocumentTermMatrix(corpus2)
dtm3 <- DocumentTermMatrix(corpus3)
dtm4 <- DocumentTermMatrix(corpus4)
## Remove sparse terms (aka terms that appear just once in the document etc)
dtms1 <-removeSparseTerms(dtm1, 0.99)
dtms2 <-removeSparseTerms(dtm2, 0.99)
dtms3 <-removeSparseTerms(dtm3, 0.99)
dtms4 <-removeSparseTerms(dtm4, 0.99)

## order the frequencies 
freq1 <- sort(colSums(as.matrix(dtms1)), decreasing=T)
freq2 <- sort(colSums(as.matrix(dtms2)), decreasing=T)
freq3 <- sort(colSums(as.matrix(dtms3)), decreasing=T)
freq4 <- sort(colSums(as.matrix(dtms4)), decreasing=T)
```

```{r cl2}
set.seed(200)

wordcloud(names(freq1), freq1, scale=c(3,.8), max.words=1000,
 random.order=F, use.r.layout= F,min.freq=10,
 colors=brewer.pal(6, "Dark2"), fixed.asp = TRUE, main = 'Identification') 
wordcloud(names(freq2), freq2, scale=c(3,.8), max.words=1000,
 random.order=F, use.r.layout= F,min.freq=10,
colors=brewer.pal(6, "Dark2"),  fixed.asp = TRUE, main  = 'Assault')

wordcloud(names(freq3), freq3, scale=c(3,.8), max.words=1000,
 random.order=F, use.r.layout= F,min.freq=10,
colors=brewer.pal(6, "Dark2"),  fixed.asp = TRUE, main = 'Disorderly Conduct')

wordcloud(names(freq4), freq4, scale=c(3,.5), max.words=1000,
 random.order=F, use.r.layout= F,min.freq=20,
colors=brewer.pal(6, "Dark2"),  fixed.asp = TRUE, main = 'Other')
```


